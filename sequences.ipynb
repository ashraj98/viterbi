{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries and read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "obs = pd.read_csv('data/observationProbs.csv', index_col=0)\n",
    "test = pd.read_csv('data/testData.csv', index_col=0)\n",
    "trans = pd.read_csv('data/transitionProbs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Viterbi Algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def viterbi(transitions, emissions, priors, events):\n",
    "    # Get dimensions of transitions and fill tables\n",
    "    T = len(np.trim_zeros(events))\n",
    "    K = transitions.shape[0]\n",
    "    M = np.empty((T, K), 'd')\n",
    "    C = np.empty((T, K), 'B')\n",
    "    \n",
    "    # Initialize table using START probabilities\n",
    "    M[0,:] = priors * emissions[events[0] - 1, :]\n",
    "    C[0,:] = 0\n",
    "    \n",
    "    # Iterate over samples from testData and calculate next values\n",
    "    for i in range(1, T):\n",
    "        M[i, :] = np.max(M[i - 1, :] * transitions * emissions[events[i] - 1, :], 1)\n",
    "        C[i, :] = np.argmax(M[i - 1, :] * transitions, 1)\n",
    "    \n",
    "    # Find last hidden state using table\n",
    "    X = np.empty(T, 'B')\n",
    "    X[-1] = np.argmax(M[T-1, :])\n",
    "    \n",
    "    # Go back through samples in reverse and find most likely hidden states\n",
    "    for i in reversed(range(1, T)):\n",
    "        X[i - 1] = C[i, X[i]]\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prep data for algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "priors = trans['START'].to_numpy()\n",
    "priors = priors[np.arange(priors.size - 1)]\n",
    "\n",
    "transitions = trans.to_numpy()\n",
    "transitions = np.delete(transitions, transitions.shape[0] - 1, 0)\n",
    "transitions = np.delete(transitions, transitions.shape[1] - 1, 1)\n",
    "emissions = obs.to_numpy()\n",
    "sequences = test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Input all sequences into algorithm and get most likely hidden states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1 1 1 1 1]\n[1 1 1 1]\n[0 0 0 0 0]\n[0 0 0]\n[0 0 0 0 0]\n[0 0 0 0]\n[1 1 1]\n[0 0 0 0]\n[0 0 1 1 1]\n[0 0 0]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "viterbi_results = {}\n",
    "\n",
    "for idx, events in enumerate(sequences):\n",
    "    viterbi_results[idx] = viterbi(transitions, emissions, priors, events)\n",
    "    print(viterbi_results[idx])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0 = C\n",
    "\n",
    "1 = H"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Likelihood Weighting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1, 1, 1, 1, 1)\n(1, 1, 1, 1)\n(0, 0, 0, 0, 0)\n",
      "(1, 1, 1)\n(1, 1, 1, 1, 1)\n(1, 1, 1, 1)\n",
      "(0, 0, 0)\n(0, 0, 0, 0)\n",
      "(0, 0, 0, 0, 0)\n(0, 0, 0)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def eisner_one_sample_gen(length):\n",
    "    rand = random.random()\n",
    "    sample = (0 if rand < .5 else 1,)\n",
    "    weight = .5\n",
    "    threshold = .86 / .93\n",
    "    for i in range(1, length):\n",
    "        rand = random.random()\n",
    "        sample += (sample[i-1] if rand < threshold else 1 - sample[i-1],)\n",
    "        weight *= threshold if rand < threshold else 1 - threshold\n",
    "    weight *= .07\n",
    "    return weight, sample\n",
    "\n",
    "def gen_lw_samples(events, num_samples):\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        samples.append(eisner_one_sample_gen(len(events)))\n",
    "    return samples\n",
    "\n",
    "def get_most_likely(samples):\n",
    "    sample_weights = {}\n",
    "    for weight, sample in samples:\n",
    "        if sample in sample_weights:\n",
    "            sample_weights[sample] += weight\n",
    "        else:\n",
    "            sample_weights[sample] = weight\n",
    "    return max(sample_weights, key=sample_weights.get)\n",
    "\n",
    "for idx, events in enumerate(sequences):\n",
    "    trimmed = np.trim_zeros(events)\n",
    "    samples = gen_lw_samples(trimmed, 75000)\n",
    "    print(get_most_likely(samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0 = C\n",
    "\n",
    "1 = H\n",
    "\n",
    "The sampler will not converge because we are not supplying any information about the actual test\n",
    "data to the sampler, apart from the sequence length. For each sequence, the sampler will converge\n",
    "to either H -> H -> ... or C -> C -> ... because after a 50/50 chance of picking hot or cold for\n",
    "Day 1, the heights weights will be for the repetitive sequence, so it comes down to which sequence\n",
    "occurs more in the generated sample, which is random.\n",
    "\n",
    "The likelihood weight may match our Viterbi answer sometimes when Viterbi expects all hot or all cold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}